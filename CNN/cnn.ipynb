{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XBITN0M_LKds"
      },
      "source": [
        "# Project\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-NH4P-HzLRQs"
      },
      "source": [
        "Colorectal Liver Metastases Recurrence Prediction from Clinical and CT Image Data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BdoDIKWOMF59"
      },
      "source": [
        "# Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwLEd0gdPbSc",
        "outputId": "fc575bf7-2826-44ef-f1b8-72cac5054b37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "import torchvision\n",
        "import os\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import models\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRz9et3SZnbO",
        "outputId": "55620180-d996-464a-ff6b-7707c65cfc79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sSeiKHYrM-6b"
      },
      "source": [
        "# Classification Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "5b8nO7smSsmH"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"batch_size\": 16,\n",
        "    \"lr\": 1e-2,\n",
        "    \"epochs\": 30\n",
        "}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load datasets and data augmentation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can download the datasets at https://drive.google.com/drive/folders/14mJNEYAsGXLe3F-6vi_TcOAe6t4DxCSY?usp=share_link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "tmRX5omaNDEZ"
      },
      "outputs": [],
      "source": [
        "DATA_DIR    = '/content/drive/MyDrive/dataset/'\n",
        "TRAIN_DIR   = os.path.join(DATA_DIR, \"train\") \n",
        "VAL_DIR     = os.path.join(DATA_DIR, \"valid\")\n",
        "\n",
        "\n",
        "train_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandAugment(6),\n",
        "    # torchvision.transforms.RandomHorizontalFlip(),\n",
        "    # torchvision.transforms.RandomRotation(10),\n",
        "    torchvision.transforms.Resize(256),\n",
        "    torchvision.transforms.CenterCrop(224),\n",
        "    torchvision.transforms.Grayscale(num_output_channels=1),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=[0.20978874], std=[0.21695834]),\n",
        "])\n",
        "\n",
        "valid_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize(256),\n",
        "    torchvision.transforms.CenterCrop(224),\n",
        "    torchvision.transforms.Grayscale(num_output_channels=1),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=[0.20978874], std=[0.21695834])\n",
        "])\n",
        "\n",
        "train_dataset   = torchvision.datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
        "valid_dataset   = torchvision.datasets.ImageFolder(VAL_DIR, transform=valid_transforms)\n",
        "\n",
        "# train_sub_idx = [i for i in range(len(train_dataset)) if train_dataset.imgs[i][0].split('/')[7] in train_cluster_name]\n",
        "# train_sub_dataset = torch.utils.data.Subset(train_dataset, train_sub_idx)\n",
        "# valid_sub_idx = [i for i in range(len(valid_dataset)) if valid_dataset.imgs[i][0].split('/')[7] in valid_cluster_name]\n",
        "# valid_sub_dataset = torch.utils.data.Subset(valid_dataset, valid_sub_idx)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create WeightedRandomSampler for imbalanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "m4seGLBec8Xo"
      },
      "outputs": [],
      "source": [
        "list_name=[]\n",
        "list_label=[]\n",
        "for i,j in train_dataset.imgs:\n",
        "  list_name.append(i)\n",
        "  list_label.append(j)\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "labels_unique,counts = np.unique(np.array(list_label),return_counts=True)\n",
        "class_weights = [sum(counts)/c for c in counts]\n",
        "example_weights = [class_weights[e] for e in list_label ]\n",
        "sampler = WeightedRandomSampler(example_weights,len(list_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "m14CX9XXc5wH"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = train_dataset, \n",
        "    batch_size  = config['batch_size'], \n",
        "    #shuffle     = True,\n",
        "    num_workers = 4, \n",
        "    sampler = sampler,\n",
        "    pin_memory  = True\n",
        ")\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = valid_dataset, \n",
        "    batch_size  = config['batch_size'],\n",
        "    shuffle     = False,\n",
        "    #sampler = sampler,\n",
        "    num_workers = 2\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mIqmojPaWD0H"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model 1, ConvNext Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "HRuM0uMeTr0X"
      },
      "outputs": [],
      "source": [
        "# Reference: https://arxiv.org/abs/2201.03545(github: https://github.com/facebookresearch/ConvNeXt) \n",
        "import torch.nn as nn\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim)\n",
        "        self.bn1 = nn.BatchNorm2d(dim)\n",
        "        self.conv2 = nn.Conv2d(dim, dim*4, kernel_size= 1, stride= 1, padding= 0)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.conv3 = nn.Conv2d(4*dim, dim, kernel_size= 1, stride= 1, padding= 0)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        self.input = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.conv3(x)\n",
        "        return x + self.input\n",
        "    \n",
        "class ConvNeXt_L(nn.Module):\n",
        "    def __init__(self, in_channels= 1, num_class= 1, depths= [3, 3, 27, 3], dims = [96, 192, 384, 768]):\n",
        "        super().__init__()\n",
        "        self.downsample_layers = nn.ModuleList()\n",
        "        self.stage_layers = nn.ModuleList()\n",
        "        self.cls_layer = nn.Linear(dims[-1], num_class)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.flat = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(p = 0.1)\n",
        "        \n",
        "        self.stem_layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, dims[0], kernel_size= 4, stride= 4),\n",
        "            nn.BatchNorm2d(dims[0])\n",
        "        )\n",
        "        self.downsample_layers.append(self.stem_layer)\n",
        "        \n",
        "        for i in range(3):\n",
        "            downsample_layer = nn.Sequential(\n",
        "                nn.BatchNorm2d(dims[i]),\n",
        "                nn.Conv2d(dims[i], dims[i+1], kernel_size= 2, stride= 2)\n",
        "            )\n",
        "            self.downsample_layers.append(downsample_layer)\n",
        "            \n",
        "        for i in range(4):\n",
        "            stage_layer = nn.Sequential(\n",
        "                *[Block(dim= dims[i]) for k in range(depths[i])]\n",
        "            )\n",
        "            self.stage_layers.append(stage_layer)\n",
        "        \n",
        "    def forward(self, x, return_feats=False):\n",
        "        for i in range(4):\n",
        "            x = self.downsample_layers[i](x)\n",
        "            x = self.stage_layers[i](x)\n",
        "        x = self.avgpool(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        if return_feats:\n",
        "            return x\n",
        "        else:\n",
        "            return self.cls_layer(x)\n",
        "        \n",
        "model = ConvNeXt_L().to(DEVICE)\n",
        "summary(model, (1, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.residual_function = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
        "\n",
        "class BottleNeck(nn.Module):\n",
        "\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.residual_function = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride=stride, kernel_size=1, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, num_block, num_classes=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = 64\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
        "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
        "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
        "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.conv1(x)\n",
        "        output = self.conv2_x(output)\n",
        "        output = self.conv3_x(output)\n",
        "        output = self.conv4_x(output)\n",
        "        output = self.conv5_x(output)\n",
        "        output = self.avg_pool(output)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.fc(output)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resnet34():\n",
        "    \"\"\" return a ResNet 34 object\n",
        "    \"\"\"\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "model = resnet34().to(DEVICE)\n",
        "summary(model, (1, 224, 224))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model3, VGG-B model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSRgXbYk2mdI",
        "outputId": "e6038834-b401-454b-8094-e460c8ed0c1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]             640\n",
            "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
            "              ReLU-3         [-1, 64, 224, 224]               0\n",
            "            Conv2d-4         [-1, 64, 224, 224]          36,928\n",
            "       BatchNorm2d-5         [-1, 64, 224, 224]             128\n",
            "              ReLU-6         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-7         [-1, 64, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]          73,856\n",
            "       BatchNorm2d-9        [-1, 128, 112, 112]             256\n",
            "             ReLU-10        [-1, 128, 112, 112]               0\n",
            "           Conv2d-11        [-1, 128, 112, 112]         147,584\n",
            "      BatchNorm2d-12        [-1, 128, 112, 112]             256\n",
            "             ReLU-13        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-14          [-1, 128, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         295,168\n",
            "      BatchNorm2d-16          [-1, 256, 56, 56]             512\n",
            "             ReLU-17          [-1, 256, 56, 56]               0\n",
            "           Conv2d-18          [-1, 256, 56, 56]         590,080\n",
            "      BatchNorm2d-19          [-1, 256, 56, 56]             512\n",
            "             ReLU-20          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-21          [-1, 256, 28, 28]               0\n",
            "           Conv2d-22          [-1, 512, 28, 28]       1,180,160\n",
            "      BatchNorm2d-23          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-24          [-1, 512, 28, 28]               0\n",
            "           Conv2d-25          [-1, 512, 28, 28]       2,359,808\n",
            "      BatchNorm2d-26          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-27          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-28          [-1, 512, 14, 14]               0\n",
            "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-30          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-31          [-1, 512, 14, 14]               0\n",
            "           Conv2d-32          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-33          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-34          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-35            [-1, 512, 7, 7]               0\n",
            "           Linear-36                    [-1, 8]         200,712\n",
            "             ReLU-37                    [-1, 8]               0\n",
            "          Dropout-38                    [-1, 8]               0\n",
            "           Linear-39                    [-1, 8]              72\n",
            "             ReLU-40                    [-1, 8]               0\n",
            "          Dropout-41                    [-1, 8]               0\n",
            "           Linear-42                    [-1, 1]               9\n",
            "================================================================\n",
            "Total params: 9,610,521\n",
            "Trainable params: 9,610,521\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 291.89\n",
            "Params size (MB): 36.66\n",
            "Estimated Total Size (MB): 328.75\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "cfg = {\n",
        "    'A' : [64,     'M', 128,      'M', 256, 256,           'M', 512, 512,           'M', 512, 512,           'M'],\n",
        "    'B' : [64, 64, 'M', 128, 128, 'M', 256, 256,           'M', 512, 512,           'M', 512, 512,           'M'],\n",
        "    'D' : [64, 64, 'M', 128, 128, 'M', 256, 256, 256,      'M', 512, 512, 512,      'M', 512, 512, 512,      'M'],\n",
        "    'E' : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
        "}\n",
        "\n",
        "class VGG(nn.Module):\n",
        "\n",
        "    def __init__(self, features, num_class=1):\n",
        "        super().__init__()\n",
        "        self.features = features\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            #nn.Linear(25088, 4096),\n",
        "            nn.Linear(25088,8),\n",
        "            # nn.Sigmoid(),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            #nn.Linear(4096, 4096),\n",
        "            nn.Linear(8,8),\n",
        "            # nn.Sigmoid(),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            #nn.Linear(4096, num_class)\n",
        "            nn.Linear(8, num_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.features(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.classifier(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "\n",
        "    input_channel = 1\n",
        "    for l in cfg:\n",
        "        if l == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            continue\n",
        "\n",
        "        layers += [nn.Conv2d(input_channel, l, kernel_size=3, padding=1)]\n",
        "\n",
        "        if batch_norm:\n",
        "            layers += [nn.BatchNorm2d(l)]\n",
        "\n",
        "        # layers += [nn.Sigmoid()]\n",
        "        layers += [nn.ReLU(inplace=True)]\n",
        "        input_channel = l\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "model = VGG(make_layers(cfg['B'], batch_norm=True)).to(DEVICE)\n",
        "summary(model, (1, 224, 224))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KZCn0qHuZRKj"
      },
      "source": [
        "# Setup everything for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "UowI9OcUYPjP"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.Adam(model.parameters())\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,'max',factor=0.5, patience=2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dzM11HtcboYv"
      },
      "source": [
        "# Let's train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "bgSw6iJJavBZ"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "def train(model, dataloader, optimizer, criterion):\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    batch_bar   = tqdm(total=len(dataloader), dynamic_ncols=True, leave=False, position=0, desc='Train', ncols=5) \n",
        "\n",
        "    total_loss  = 0.0\n",
        "    num_correct = 0\n",
        "\n",
        "    for i, (images, labels) in enumerate(dataloader):\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        \n",
        "        outputs = model(images)\n",
        "        loss    = criterion(outputs, labels.unsqueeze(1).float())\n",
        "\n",
        "        pred = torch.tensor([1 if x > 0.75 else 0 for x in F.sigmoid(outputs)])\n",
        "        pred = pred.to(DEVICE)\n",
        "        num_correct     += int((pred == labels).sum())\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            acc         = \"{:.04f}%\".format(100 * num_correct / (config['batch_size']*(i + 1))),\n",
        "            loss        = \"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            lr          = \"{:.04f}\".format(float(optimizer.param_groups[0]['lr']))\n",
        "        )\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      \n",
        "        batch_bar.update()\n",
        "\n",
        "    batch_bar.close()\n",
        "\n",
        "    acc         = 100 * num_correct / (config['batch_size']* len(dataloader))\n",
        "    total_loss  = float(total_loss / len(dataloader))\n",
        "\n",
        "    return acc, total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "m5V2UdnpdEoK"
      },
      "outputs": [],
      "source": [
        "def validate(model, dataloader, criterion):\n",
        "  \n",
        "    model.eval()\n",
        "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, position=0, leave=False, desc='Val', ncols=5)\n",
        "\n",
        "    total_loss = 0.0\n",
        "    num_correct = 0.0\n",
        "    test_results = []\n",
        "    true_labels = []\n",
        "\n",
        "    for i, (images, labels) in enumerate(dataloader):\n",
        "\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        \n",
        "        with torch.inference_mode():\n",
        "            outputs = model(images)\n",
        "            loss    = criterion(outputs, labels.unsqueeze(1).float())\n",
        "\n",
        "        pred = F.sigmoid(outputs)\n",
        "        pred = torch.tensor([1 if x > 0.75 else 0 for x in pred]).to(DEVICE)\n",
        "        num_correct     += int((pred == labels).sum())\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "\n",
        "        opts = pred.detach().cpu().numpy().tolist()\n",
        "        labels = labels.detach().cpu().numpy().tolist()\n",
        "        test_results.extend(opts)\n",
        "        true_labels.extend(labels)\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            acc=\"{:.04f}%\".format(100 * num_correct / (config['batch_size']*(i + 1))),\n",
        "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))))\n",
        "\n",
        "        batch_bar.update()\n",
        "        \n",
        "    batch_bar.close()\n",
        "\n",
        "\n",
        "    acc         = 100 * num_correct / (config['batch_size']* len(dataloader))\n",
        "    total_loss = float(total_loss / len(dataloader))\n",
        "    \n",
        "    return acc, total_loss,test_results, true_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmotca6pcLLY",
        "outputId": "fe3affb0-b685-4fbe-d2ac-a020b03a77ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SQkRw1FvLqYe"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 893
        },
        "id": "EqWO8Edb0BK2",
        "outputId": "8df4dc5d-3b51-4999-e31d-b09c4a66295b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/30: \n",
            "Train Acc 50.3289%\t Train Loss 0.6956\t Learning Rate 0.1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Acc 61.8976%\t Val Loss 0.6973\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2/30: \n",
            "Train Acc 49.7880%\t Train Loss 0.6937\t Learning Rate 0.1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Acc 61.8976%\t Val Loss 0.6806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3/30: \n",
            "Train Acc 50.3509%\t Train Loss 0.6934\t Learning Rate 0.1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Acc 61.8976%\t Val Loss 0.6809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4/30: \n",
            "Train Acc 50.4167%\t Train Loss 0.6938\t Learning Rate 0.1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Acc 61.8976%\t Val Loss 0.6905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5/30: \n",
            "Train Acc 50.1316%\t Train Loss 0.6932\t Learning Rate 0.0500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Acc 61.8976%\t Val Loss 0.6887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6/30: \n",
            "Train Acc 48.8304%\t Train Loss 0.6932\t Learning Rate 0.0500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Acc 61.8976%\t Val Loss 0.6973\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7/30: \n",
            "Train Acc 50.5044%\t Train Loss 0.6934\t Learning Rate 0.0500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Acc 61.8976%\t Val Loss 0.6896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  95%|█████████▍| 810/855 [01:07<00:03, 11.54it/s, acc=50.1543%, loss=0.6933, lr=0.0250]"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-a2a7148b9747>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcurr_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     print(\"\\nEpoch {}/{}: \\nTrain Acc {:.04f}%\\t Train Loss {:.04f}\\t Learning Rate {:.04f}\".format(\n",
            "\u001b[0;32m<ipython-input-76-f4991830333b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "best_valacc = 0\n",
        "\n",
        "for epoch in range(config['epochs']):\n",
        "\n",
        "    curr_lr = float(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    train_acc, train_loss = train(model, train_loader, optimizer, criterion)\n",
        "    \n",
        "    print(\"\\nEpoch {}/{}: \\nTrain Acc {:.04f}%\\t Train Loss {:.04f}\\t Learning Rate {:.04f}\".format(\n",
        "        epoch + 1,\n",
        "        config['epochs'],\n",
        "        train_acc,\n",
        "        train_loss,\n",
        "        curr_lr))\n",
        "    \n",
        "    val_acc, val_loss,test_results, true_labels = validate(model, valid_loader, criterion)\n",
        "    \n",
        "    print(\"Val Acc {:.04f}%\\t Val Loss {:.04f}\".format(val_acc, val_loss))\n",
        "    scheduler.step(val_acc)\n",
        "\n",
        "\n",
        "    # if val_acc >= best_valacc:\n",
        "    #   #path = os.path.join(root, model_directory, 'checkpoint' + '.pth')\n",
        "    #   print(\"Saving model\")\n",
        "    #   torch.save({'model_state_dict':model.state_dict(),\n",
        "    #               'optimizer_state_dict':optimizer.state_dict(),\n",
        "    #               #'scheduler_state_dict':scheduler.state_dict(),\n",
        "    #               'val_acc': val_acc, \n",
        "    #               'epoch': epoch}, '/content/drive/MyDrive/mlproj_base1.pth')\n",
        "    #   best_valacc = val_acc"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model validation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "XRteaizB9YYZ",
        "outputId": "d330ad06-6a17-4957-919a-8a242efc8668"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(83.22222222222221, 0.5, 'Predicted class')"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 900x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# test_results, true_labels = test(model, valid_loader, criterion)\n",
        "\n",
        "cm = confusion_matrix(test_results, true_labels)\n",
        "plt.figure(figsize=(9, 8))\n",
        "sns.heatmap(cm, annot=True)\n",
        "plt.xlabel(\"Actual class\")\n",
        "plt.ylabel(\"Predicted class\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "F1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nWgl2eX9tPz",
        "outputId": "9d3e58ea-9351-4da1-dbc6-2fc9f3506a18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 score: 0.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1 = f1_score(true_labels, test_results)\n",
        "\n",
        "# Print F1 score\n",
        "print(\"F1 score:\", f1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Re-analysis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PCA and Kmeans clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "import cv2\n",
        "from imutils import build_montages\n",
        "import matplotlib.image as imgplt\n",
        "\n",
        "\n",
        "DATA_DIR    = '/content/drive/MyDrive/dataset/'\n",
        "TRAIN_DIR   = os.path.join(DATA_DIR, \"train/0\") \n",
        "VAL_DIR     = os.path.join(DATA_DIR, \"valid/0\")\n",
        "\n",
        "# load data for class 0 and class 1 in training set\n",
        "dir0 = os.path.join(DATA_DIR, \"train/0\") \n",
        "\n",
        "image_path = []\n",
        "all_images = []\n",
        "images = os.listdir(dir)\n",
        "\n",
        "for image_name in images:\n",
        "    image_path.append(dir+'/' + image_name)\n",
        "for path in image_path:\n",
        "    image = imgplt.imread(path)\n",
        "    image = image.reshape(-1, )\n",
        "    all_images.append(image)\n",
        "\n",
        "dir1 = os.path.join(DATA_DIR, \"train/1\") \n",
        "\n",
        "image_path = []\n",
        "all_images1 = []\n",
        "images = os.listdir(dir)\n",
        "\n",
        "for image_name in images:\n",
        "    image_path.append(dir+'/' + image_name)\n",
        "for path in image_path:\n",
        "    image = imgplt.imread(path)\n",
        "    image = image.reshape(-1, )\n",
        "    all_images1.append(image)\n",
        "\n",
        "train_0_array = np.array(all_images)\n",
        "train_1_array = np.array(all_images1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PCA for image features dimension reducion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# class 0\n",
        "scaler = MinMaxScaler()\n",
        "normalized_data = scaler.fit_transform(train_0_array)\n",
        "pca = PCA(n_components=2)\n",
        "pca_data_0 = pca.fit_transform(normalized_data)\n",
        "clt = KMeans(n_clusters=5)\n",
        "clt.fit(pca_data_0)\n",
        "clusters_train_0 = clt.predict(pca_data_0)\n",
        "\n",
        "# class 1\n",
        "normalized_data = scaler.fit_transform(train_1_array)\n",
        "pca = PCA(n_components=2)\n",
        "pca_data_1 = pca.fit_transform(normalized_data)\n",
        "clt = KMeans(n_clusters=5)\n",
        "clt.fit(pca_data_1)\n",
        "clusters_train_1 = clt.predict(pca_data_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# clusterin results plotting\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "scatter1 = ax.scatter(pca_data_0[:,0], pca_data_0[:,1],s=5, c=clusters_train_0, marker = '*',cmap='Accent',alpha=0.5)\n",
        "scatter2 = ax.scatter(pca_data_1[:,0], pca_data_1[:,1],s=5, c=clusters_train_1, marker = 'o',cmap='Accent',alpha=0.5)\n",
        "\n",
        "# add labels and title\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.title('K-means Clustering Results-c;')\n",
        "legend1 = ax.legend(*scatter1.legend_elements(), loc=\"upper left\", title=\"Clusters-Class 0\")\n",
        "legend2 = ax.legend(*scatter2.legend_elements(), loc=\"upper right\", title=\"Clusters-Class 1\")\n",
        "ax.add_artist(legend1)\n",
        "ax.add_artist(legend2)\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
